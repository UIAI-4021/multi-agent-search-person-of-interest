{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea3f0f62-5e7b-4cfe-8e70-afd9dd73e795",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 106)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m<tokenize>:106\u001B[1;36m\u001B[0m\n\u001B[1;33m    \"\"\"\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# multiAgents.py\n",
    "# --------------\n",
    "# Licensing Information:  You are free to use or extend these projects for\n",
    "# educational purposes provided that (1) you do not distribute or publish\n",
    "# solutions, (2) you retain this notice, and (3) you provide clear\n",
    "# attribution to UC Berkeley, including a link to http://ai.berkeley.edu.\n",
    "#\n",
    "# Attribution Information: The Pacman AI projects were developed at UC Berkeley.\n",
    "# The core projects and autograders were primarily created by John DeNero\n",
    "# (denero@cs.berkeley.edu) and Dan Klein (klein@cs.berkeley.edu).\n",
    "# Student side autograding was added by Brad Miller, Nick Hay, and\n",
    "# Pieter Abbeel (pabbeel@cs.berkeley.edu).\n",
    "\n",
    "\n",
    "from util import manhattanDistance\n",
    "from game import Directions\n",
    "import random, util\n",
    "\n",
    "from game import Agent\n",
    "from pacman import GameState\n",
    "\n",
    "\n",
    "def scoreEvaluationFunction(currentGameState: GameState):\n",
    "    \"\"\"\n",
    "    This default evaluation function just returns the score of the state.\n",
    "    The score is the same one displayed in the Pacman GUI.\n",
    "\n",
    "    This evaluation function is meant for use with adversarial search agents\n",
    "    \"\"\"\n",
    "    return currentGameState.getScore()\n",
    "\n",
    "def getLegalActionsNoStop(index, gameState):\n",
    "        possibleActions = gameState.getLegalActions(index)\n",
    "        if Directions.STOP in possibleActions:\n",
    "            possibleActions.remove(Directions.STOP)\n",
    "        return possibleActions\n",
    "\n",
    "\n",
    "class MultiAgentSearchAgent(Agent):\n",
    "    def __init__(self, evalFn=\"scoreEvaluationFunction\", depth=\"2\", time_limit=\"6\"):\n",
    "        self.index = 0  # Pacman is always agent index 0\n",
    "        self.evaluationFunction = util.lookup(evalFn, globals())\n",
    "        self.depth = int(depth)\n",
    "        self.time_limit = int(time_limit)\n",
    "\n",
    "\n",
    "class AIAgent(MultiAgentSearchAgent):\n",
    "    def alphabeta(self, agent, depth, gameState, alpha, beta):\n",
    "        if gameState.isLose() or gameState.isWin() or depth == self.depth:\n",
    "            return self.evaluationFunction(gameState)\n",
    "        if agent == 0:  # maximize for pacman\n",
    "            value = -999999\n",
    "            for action in getLegalActionsNoStop(agent, gameState):\n",
    "                value = max(value, self.alphabeta(1, depth, gameState.generateSuccessor(agent, action), alpha, beta))\n",
    "                alpha = max(alpha, value)\n",
    "                if beta <= alpha:  # alpha-beta pruning\n",
    "                    break\n",
    "            return value\n",
    "        else:  # minimize for ghosts\n",
    "            nextAgent = agent + 1  # get the next agent\n",
    "            if gameState.getNumAgents() == nextAgent:\n",
    "                nextAgent = 0\n",
    "            if nextAgent == 0:  # increase depth every time all agents have moved\n",
    "                depth += 1\n",
    "            for action in getLegalActionsNoStop(agent, gameState):\n",
    "                value = 999999\n",
    "                value = min(value, self.alphabeta(nextAgent, depth, gameState.generateSuccessor(agent, action), alpha, beta))\n",
    "                beta = min(beta, value)\n",
    "                if beta <= alpha:  # alpha-beta pruning\n",
    "                    break\n",
    "            return value\n",
    "\n",
    "\n",
    "    \n",
    "    def getAction(self, gameState: GameState):\n",
    "        \"\"\"\n",
    "        Here are some method calls that might be useful when implementing minimax.\n",
    "\n",
    "        gameState.getLegalActions(agentIndex):\n",
    "        Returns a list of legal actions for an agent\n",
    "        agentIndex=0 means Pacman, ghosts are >= 1\n",
    "\n",
    "        gameState.generateSuccessor(agentIndex, action):\n",
    "        Returns the successor game state after an agent takes an action\n",
    "\n",
    "        gameState.getNumAgents():\n",
    "        Returns the total number of agents in the game\n",
    "\n",
    "        gameState.isWin():\n",
    "        Returns whether or not the game state is a winning state\n",
    "\n",
    "        gameState.isLose():\n",
    "        Returns whether or not the game state is a losing state\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Your code goes here\n",
    "        # util.raiseNotDefined()\n",
    "\n",
    "        \"\"\"\n",
    "        Returns the expectimax action using self.depth and self.evaluationFunction\n",
    "        All ghosts should be modeled as choosing uniformly at random from their\n",
    "        legal moves.\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        Returns the minimax action from the current gameState using self.depth\n",
    "        and self.evaluationFunction using alpha-beta pruning.\n",
    "        \"\"\"\n",
    "        possibleActions = getLegalActionsNoStop(0, gameState)\n",
    "        alpha = -999999\n",
    "        beta = 999999\n",
    "        action_scores = [self.alphabeta(0, 0, gameState.generateSuccessor(0, action), alpha, beta) for action\n",
    "                         in possibleActions]\n",
    "        max_action = max(action_scores)\n",
    "        max_indices = [index for index in range(len(action_scores)) if action_scores[index] == max_action]\n",
    "        chosenIndex = random.choice(max_indices)\n",
    "        return possibleActions[chosenIndex]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1ba06-c1ed-45a0-ae77-30f21d77a91a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba434c-d5f6-404e-bd9f-a5344ca1c1e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d4f2f-00c9-4e52-996f-f368df634bc4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2ebc8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcecb0-5464-45cf-91f6-3280bda25b3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}